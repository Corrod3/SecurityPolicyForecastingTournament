Inf))]
# counting the age group / gender occurances
SPFT.Demo.Plot <- SPFT %>% select(age.gr,sex) %>% group_by(age.gr, sex) %>%
dplyr::count()
# plot population pyramid
pop.plot <- ggplot(data = SPFT.Demo.Plot, aes(x = age.gr, y = n, fill = sex)) +
geom_bar(data = subset(SPFT.Demo.Plot, sex == "Female"), stat = "identity") +
geom_bar(data = subset(SPFT.Demo.Plot, sex == "Male"),
stat = "identity",
position = "identity",
mapping = aes(y = -n)) +
scale_y_continuous(labels = abs) +
labs(title = "Age and gender of participants",
x = "Age groups",
y = "# of respondents") + # labels
coord_flip()
# just gender
gender.plot <- ggplot(data = SPFT, aes(x = sex)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
scale_y_continuous(labels = percent)
# intuition vs. analysis ######################################################
# order replies
SPFT$intu.anal <- factor(SPFT$intu.anal,
levels =  c("Only intuition",
"Mostly intuition, some analysis",
"About evenly intuition and analysis",
"Mostly analysis, some intuition",
"Only analysis"))
# plot object
intu.anal.plot <- ggplot(SPFT, aes(x = intu.anal)) +
geom_bar() +
coord_flip() +
labs(title = "Intuition vs. Analysis",
x = "Approach",
y = "# of respondents") # labels
intu.share <- (as.data.frame(table(SPFT$intu.anal))[1,2] +
as.data.frame(table(SPFT$intu.anal))[2,2]) / nrow(SPFT) * 100
# self-assessment ############################################################
# order
# levels(as.factor(SPFT$selfassessment))
selfassessment.plot <- ggplot(SPFT, aes(x = selfassessment)) +
geom_bar() +
coord_flip() +
labs(title = "Self-assessment",
x = "Assessment",
y = "# of respondents") # labels
# experience ##################################################################
# order
SPFT$exp <- factor(SPFT$exp,
levels =  c("No, I never participated in any forecasting of events",
"Yes, I have tried forecasting events a few times",
"Yes, I sometimes forecast events",
"Yes, I regularly forecast events"))
# levels(as.factor(SPFT$exp))
exp.plot <- ggplot(SPFT, aes(x = exp)) +
geom_bar() +
coord_flip() +
labs(title = "Forecasting experience",
x = "Assessment",
y = "# of respondents") # labels
# experience security policy ##################################################
# order
SPFT$exp.sp <- factor(SPFT$exp.sp,
levels =  c("None",
"Yes, but less than six months",
"Yes, between six months and two years",
"Yes, more than two years"))
# levels(as.factor(SPFT$exp.sp))
exp.sp.plot <- ggplot(SPFT, aes(x = exp.sp)) +
geom_bar() +
coord_flip() +
labs(title = "Security policy experience",
x = "Assessment",
y = "# of respondents") # labels
# education ###################################################################
edu.plot <- ggplot(SPFT, aes(x = edu)) +
geom_bar() +
coord_flip() +
labs(title = "Education",
x = "Education",
y = "# of respondents") # labels
# employment ##################################################################
emp.plot <- ggplot(SPFT, aes(x = emp)) +
geom_bar() +
coord_flip() +
labs(title = "Employment / occupation",
x = "Occupation",
y = "# of respondents") # labels
# summary table for all numerical variables ###################################
# move it to the online appendix
# stargazer(select(SPFT, bnt.s, mct.c, time.fq.sec, Duration.min, age),
#          type="html", out = "DescStat.html")
###############################################################################
# 8. Testing
###############################################################################
# Skill vs. Luck ##############################################################
# Compute expected Brier score for p = 0.5 for each question
# 1. Individual Brier score for each possible outcome (0 or 1)
# 2. Calculate average for each question
# 3. Calculate average over all questions
brier.exp.fq <- 0
for(i in 1:nrow(FQ)){
brier.exp.fq[i] <- mean(2*((select(SPFT, contains(paste("fq", i, "_1",sep = ""))))^2 +
(1 - select(SPFT, contains(paste("fq", i, "_1",sep = ""))))^2 )/2)
}
# T-Test one-sided (Expected Brier score with p = 50%)
t.test.against.random  <- t.test(SPFT$brier.avg, mu = mean(brier.exp.fq),
alternative = "less", conf.level=0.95)
# get text string for the paper
t.test.against.random  <- paste("t(", t.test.against.random[[2]], ") = ",
round(t.test.against.random[[1]],2),
", p < ",
ifelse(round(t.test.against.random[[3]],4)< 0.001,
0.001,round(t.test.against.random[[3]],4)),
sep = "")
# alternative: Use average probability for each question to compute brier score
# alternative skills vs. luck test: correct side of 50% #######################
# score board for correct side
SB.CS <- SPFT  %>% select(ResponseId, id.hertie, id.other, id.mturk,
starts_with("fq"))
## calculate correct side scores for each question/respondent
# i <- 1
for(i in 1:nrow(FQ)){
tmp <- paste("fq", i, sep = "")
# add outcome with 1 of on correct side of 50% and 0 if not
SB.CS[,paste(tmp,"cs", sep = ".")] <-
ifelse(abs(as.numeric(FQ[FQ[,1] == tmp, 4]) - select(SB.CS, i+4)) > 0.5,0,1)
rm(tmp)
}
# individual share of being on the correct side with the forecast
SB.CS[,"cs.avg"] <- rowMeans(select(SB.CS, contains("cs")))
# One-sided T-Testing correct side measure
t.test.correct.side <- t.test(SB.CS$cs.avg, mu=0.5, alternative = "greater",
conf.level = 0.95, equal.var = T)
# string for paper
t.test.correct.side  <- paste("t(", t.test.correct.side[[2]], ") = ",
round(t.test.correct.side[[1]],2),
", p < ",
ifelse(round(t.test.correct.side[[3]],4)< 0.001,
0.001,round(t.test.correct.side[[3]],4)),
sep = "")
# Hypotheses testing ##########################################################
# function to generate a correlation matrix
# Source: http://myowelt.blogspot.de/2008/04/beautiful-correlation-tables-in-r.html
corstarsl <- function(x){
require(Hmisc)
x <- as.matrix(x)
R <- rcorr(x)$r
p <- rcorr(x)$P
## define notions for significance levels; spacing is important.
mystars <- ifelse(p < .001, "***",
ifelse(p < .01, "** ",
ifelse(p < .05, "* ", " ")))
## trunctuate the matrix that holds the correlations to two decimal
R <- format(round(cbind(rep(-1.11, ncol(x)), R), 2))[,-1]
## build a new matrix that includes the correlations with their apropriate stars
Rnew <- matrix(paste(R, mystars, sep=""), ncol=ncol(x))
diag(Rnew) <- paste(diag(R), " ", sep="")
rownames(Rnew) <- colnames(x)
colnames(Rnew) <- paste(colnames(x), "", sep="")
## remove upper triangle
Rnew <- as.matrix(Rnew)
Rnew[upper.tri(Rnew, diag = TRUE)] <- ""
Rnew <- as.data.frame(Rnew)
## remove last column and return the matrix (which is now a data frame)
Rnew <- cbind(Rnew[1:length(Rnew)-1])
return(Rnew)
}
# remove comment from xtable
options(xtable.comment = FALSE)
# compute log(time)
SPFT$time.fq.sec.log <- log(SPFT$time.fq.sec)
# correlation table with significant test
cor.table <- corstarsl(select(SPFT, brier.avg, bnt.s, mct.c, time.fq.sec.log))
names(cor.table) <- c("Brier score", "BNT score", "MCT score")
rownames(cor.table) <- c("Brier score", "BNT score", "MCT score", "log(time)")
# table to Latex format
cor.plot <- xtable(cor.table, caption = "Correlation Table")
# complete correlation table for data mining
# SPFT$selfassessment.num <- as.numeric(SPFT$selfassessment)
# cor.plot2 <- xtable(corstarsl(select(SPFT, brier.avg, bnt.s, mct.c, time.fq.sec,
#                                     time.fq.sec.log, time.min, source.var, age, selfassessment.num)),
#                   caption = "Correlation Table")
# testing only for subgroups
SPFT.Time <- SPFT %>% select(brier.avg, bnt.s, mct.c, time.fq.sec, Group) %>% filter(time.fq.sec > 6)
SPFT.Anal <- SPFT %>% select(brier.avg, bnt.s, mct.c, time.fq.sec, Group) %>% filter(time.fq.sec > 6)
# Hypothesis 1a ################################################################
# t test manual
cor(SPFT$brier.avg, SPFT$bnt.s)*
((length(SPFT$bnt.s)-2)/(1 - cor(SPFT$brier.avg, SPFT$bnt.s)^2))^(1/2)
# T test for Hyppthesis 1a
t.test.brier.bnt <- paste("t(", cor.test(SPFT$brier.avg, SPFT$bnt.s)[[2]],
") = ",
round(cor.test(SPFT$brier.avg, SPFT$bnt.s)[[1]], 2),
", p = ",
round(cor.test(SPFT$brier.avg, SPFT$bnt.s)[[3]], 3),
sep = "")
# Correlation between Brier score and BNT score
cor.brier.bnt <- paste("r = ", round(cor(SPFT$brier.avg, SPFT$bnt.s),2), ", ",
t.test.brier.bnt, sep = "")
# Test with only long decision time
# T test for Hyppthesis 1a
t.test.brier.bnt.time <- paste("t(", cor.test(SPFT.Time$brier.avg, SPFT.Time$bnt.s)[[2]],
") = ",
round(cor.test(SPFT.Time$brier.avg, SPFT.Time$bnt.s)[[1]], 2),
", p = ",
round(cor.test(SPFT.Time$brier.avg, SPFT.Time$bnt.s)[[3]], 3),
sep = "")
# Correlation between Brier score and BNT score
cor.brier.bnt.time <- paste("r = ", round(cor(SPFT.Time$brier.avg, SPFT.Time$bnt.s),2), ", ",
t.test.brier.bnt.time, sep = "")
# Hypothesis 1b ###############################################################
# T test for Hyppthesis 1b
t.test.brier.mct <- paste("t(", cor.test(SPFT$brier.avg, SPFT$mct.c)[[2]],
") = ",
round(cor.test(SPFT$brier.avg, SPFT$mct.c)[[1]], 2),
", p = ",
round(cor.test(SPFT$brier.avg, SPFT$mct.c)[[3]], 3),
sep = "")
# Correlation between Brier score and BNT score
cor.brier.mct <- paste("r = ",
round(cor(SPFT$brier.avg, SPFT$mct.c, use="complete.obs"), 2),
", ", t.test.brier.mct,
sep = "")
# Scatterplot for Hypothesis
cor.brier.mct.plot <- ggplot(filter(SPFT, !is.na(mct.c)), aes(x=mct.c, y=brier.avg)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm, color = "#C02F39") +   # Add linear regression line
theme_bw() +
theme(axis.title = element_text(size=18), # Labels axis font size
axis.text = element_text(size=14)) +
labs(x = "Moral Competency Score",
y = "Brier Score") # labels
# with minium Forecasting time: T test for Hyppthesis 1b
t.test.brier.mct.time <- paste("t(", cor.test(SPFT.Time$brier.avg, SPFT.Time$mct.c)[[2]],
") = ",
round(cor.test(SPFT.Time$brier.avg, SPFT.Time$mct.c)[[1]], 2),
", p = ",
round(cor.test(SPFT.Time$brier.avg, SPFT.Time$mct.c)[[3]], 3),
sep = "")
# Correlation between Brier score and BNT score
cor.brier.mct.time <- paste("r = ",
round(cor(SPFT.Time$brier.avg, SPFT.Time$mct.c, use="complete.obs"), 2),
", ", t.test.brier.mct.time,
sep = "")
# Hypothesis 2 ################################################################
# T test for Hypothesis 2
t.test.brier.time <- paste("t(",
cor.test(SPFT$brier.avg,
SPFT$time.fq.sec.log)[[2]],
") = ",
round(cor.test(SPFT$brier.avg,
SPFT$time.fq.sec.log)[[1]], 2),
", p = ",
round(cor.test(SPFT$brier.avg,
SPFT$time.fq.sec.log)[[3]], 3),
sep = "")
# Correlation between Brier score and BNT score
cor.brier.time <- paste("r = ",
round(cor(SPFT$brier.avg,
SPFT$time.fq.sec.log, use="complete.obs"),2),
", ",
t.test.brier.time,
sep = "")
#
cor.brier.time.linear <- paste("r = ",
round(cor(SPFT$brier.avg,
SPFT$time.fq.sec, use="complete.obs"),2)
, sep = "")
# scatterplot with non-linear regression line
# Source: http://stackoverflow.com/questions/37329074/geom-smooth-and-exponential-fits
log.model <- lm(brier.avg ~ log(time.fq.sec), SPFT)
log.model.df <- data.frame(x = SPFT$time.fq.sec[!is.na(SPFT$time.fq.sec)],
y = fitted(log.model))
cor.brier.time.plot <- ggplot(filter(SPFT, !is.na(time.fq.sec)),
aes(x=time.fq.sec, y=brier.avg)) +
geom_point(shape=1) +    # Use hollow circles
#  geom_smooth(method="lm",  linetype = 2, color = "#C02F39") +
# geom_smooth(method=lm, color = "#C02F39") +   # Add linear regression line
geom_line(data = log.model.df,
aes(x, y, color = "Log Model"),
size = 2, linetype = 1, color = "#C02F39") +
theme_bw() +
theme(axis.title = element_text(size=18), # Labels axis font size
axis.text = element_text(size=14)) +
labs(x = "time in min (linear)",
y = "Brier score") # labels
cor.brier.time.log.plot <- ggplot(filter(SPFT, !is.na(time.fq.sec)),
aes(x=time.fq.sec.log, y=brier.avg)) +
geom_point(shape=1) +    # Use hollow circles
#  geom_smooth(method="lm",  linetype = 1) +
geom_smooth(method=lm, color = "#C02F39", size = 2) +   # Add linear regression line
#  geom_line(data = log.model.df,
#            aes(x, y, color = "Log Model"),
#            size = 1, linetype = 2) +
theme_bw() +
theme(axis.title = element_text(size=18), # Labels axis font size
axis.text = element_text(size=14)) +
labs(x = "log(time)",
y = "Brier score") # labels
# Hypothesis 3 ################################################################
# get rid of empthy factor levels
SPFT$Group <- as.factor(as.character(SPFT$Group))
t.test.intervention <- t.test(x = select(filter(SPFT, Group == "Treatment"), brier.avg),
y = select(filter(SPFT, Group == "Control"), brier.avg),
alternative = "less", var.equal = T,
conf.level = 0.95)
t.test.intervention.result <- paste("t(", t.test.intervention[[2]], ") = ",
round(t.test.intervention[[1]],2),
", p < ",
ifelse(round(t.test.intervention[[3]],4)< 0.001,
0.001,round(t.test.intervention[[3]],4)),
sep = "")
# testing reasons for failure
hypo3.time.plot <- ggplot(filter(SPFT, is.na(time.fq.sec.log) == FALSE),
aes(x = time.fq.sec.log, fill = Group)) +
geom_density(alpha = 0.3) +
#geom_histogram(binwidth=.05, position="dodge", fill = "#C02F39") + # bar type
theme_bw() +
theme(axis.title = element_text(size=18), # Labels axis font size
axis.text = element_text(size=14)) +
labs( x = "log(time)",
y = "Frequency") # labels))
# t testing whether the treatment had any impact on the time spend on forecasting
t.test.int.time <-  t.test(SPFT$time.fq.sec.log[SPFT$Group == "Treatment"],
SPFT$time.fq.sec.log[SPFT$Group == "Control"],
alternative = "greater", var.equal = TRUE,
conf.level = 0.95)
t.test.intervention.time <- paste(round(t.test.int.time[[5]][1],2),
" > ",
round(t.test.int.time[[5]][2],2),
", t(", t.test.int.time[[2]], ") = ",
round(t.test.int.time[[1]],2),
", p < ",
ifelse(round(t.test.int.time[[3]],4)< 0.001,
0.001,round(t.test.int.time[[3]],4)),
sep = "")
###############################################################################
# 9. Aggregating Forecasts
###############################################################################
# Mean Estimates for each question ############################################
probs.mean <- SPFT %>% select(starts_with("fq")) %>% colMeans()
# mean brier score for average probabilities (unweighted)
bs.mean <- round(mean(brierScore(probs.mean, FQ[,4])),2)
# testing average brier score vs. brier score of averaged forecasts
t.test.bs.avg.mean <- t.test(SPFT$brier.avg, mu = bs.mean, alternative = "greater")
# string for paper
t.test.bs.avg.mean  <- paste("t(", t.test.bs.avg.mean[[2]], ") = ",
round(t.test.bs.avg.mean[[1]],2),
", p < ",
ifelse(round(t.test.bs.avg.mean[[3]],4)< 0.001,
0.001,round(t.test.bs.avg.mean[[3]],4)),
sep = "")
# 0. Subsample of (super)forecasters ##########################################
# drop BNT score 0,1 and 25% lowest share of time spend on forecasting
probs.mean.agg0 <- SPFT %>%
filter(bnt.s > 2 & time.fq.sec.log > summary(SPFT$time.fq.sec.log)[3]) %>%
select(starts_with("fq")) %>% colMeans()
# brier score of the aggregated forecasts from the sub group.
bs.cutoff.mean <- round(mean(brierScore(probs.mean.agg0, FQ[,4])),3)
# average brier score of the sub group
bs.agg0 <- 0
for(i in 1:nrow(FQ)){
bs.agg0[i] <- SPFT %>%
filter(bnt.s > 1 & time.fq.sec.log > summary(SPFT$time.fq.sec.log)[2]) %>%
dplyr::select(contains(paste("fq",i,"_1", sep= ""))) %>%
brierScore(as.numeric(FQ[i,4])) %>% as.vector() %>% mean()
}
# mean brier score of group smaller group
bs.cutoff <- round(mean(bs.agg0),3)
# 1. computing individual weights #############################################
SPFT.agg1 <- SPFT %>% select(starts_with("fq"), bnt.s,mct.c, time.fq.sec.log,
Group, brier.avg) %>%
filter(!is.na(time.fq.sec.log))
# pre-calculations to see correlations
# lm(brier.avg ~ bnt.s, data = SPFT.agg1)
# lm(brier.avg ~ time.fq.sec.log, data = SPFT.agg1)
reg.brier.bnt.time <- lm(brier.avg ~ bnt.s + time.fq.sec.log, data = SPFT.agg1)
# SPFT.agg1$d <-  0
# SPFT.agg1$d[SPFT.agg1$Group == "Treatment"] <- 1
# lm(brier.avg ~ bnt.s + mct.c + time.fq.sec.log + d, data = SPFT.agg1)
# weightening using only BNT score
# simplest version: weight = score
# SPFT$w.bnt <- SPFT$bnt.s
probs.mean.w.bnt <- apply(select(SPFT.agg1, starts_with("fq")), 2,
weighted.mean, w = SPFT.agg1$bnt.s)
mean(brierScore(probs.mean.w.bnt, FQ[,4]))
# weightening using only time.fq.sec.log score
probs.mean.w.time <- apply(select(SPFT.agg1, starts_with("fq")), 2,
weighted.mean, w = SPFT.agg1$time.fq.sec.log)
mean(brierScore(probs.mean.w.time, FQ[,4]))
# weightening using bnt and time.fq.sec.log score #############################
# contruct weigts (other weights possible)
# SPFT.agg1$w.bnt.time <- reg.brier.bnt.time[[1]][2]*SPFT.agg1$bnt.s +
#                        reg.brier.bnt.time[[1]][3]*SPFT.agg1$time.fq.sec.log
SPFT.agg1$w.bnt.time <- SPFT.agg1$bnt.s *SPFT.agg1$time.fq.sec.log
probs.mean.w.bnt.time <- apply(select(SPFT.agg1, starts_with("fq")),
2, weighted.mean, w = SPFT.agg1$w.bnt.time)
bs.mean.w.bnt.time <- round(mean(brierScore(probs.mean.w.bnt.time, FQ[,4])),2)
#identifying optimal relationship between weights (will be "overfitting")
# 2. extremizing  #############################################################
# like Satopaa et al 2014
#create data.frame for extremizing (remove 0 and 1 as logit will cause problems)
SPFT.agg2 <- SPFT %>% select(starts_with("fq")) %>% as.matrix()
SPFT.agg2[SPFT.agg2 == 0] <- 0.001
SPFT.agg2[SPFT.agg2 == 1] <- 0.999
# export values
# write.csv(SPFT.agg2, "fqAnswers.csv", row.names=FALSE)
# write.csv(FQ[,4], "Answers.csv", row.names=FALSE)
# function to create extremized means for each question
# possible to include geometric weights (q^w) -> check theory
probsLogitExtrem <-function(p,a){
q<-p/(1-p)
geo.mean<-prod(q^(1/length(q))) # every element to the power of N?
mod.prob<-(geo.mean^a)/(1+geo.mean^a)
return(mod.prob)
}
# true outcomes
Z<- as.vector(as.matrix(FQ[,4]))
# brier score average
brierScoresAvg<-function(p,z){
return(sum((p-z)^2)/length(p) + sum((z-p)^2)/length(p))
}
# optimize brier score average function to find minimizing a (bias correction)
optimise(function(a) brierScoresAvg(apply(SPFT.agg2,2,function(z) probsLogitExtrem(z, a)),Z),
interval=c(0,10))
# plot brierscore depending on bias correction
a<-seq(-2,8,by=0.1)
plot(a,sapply(a,function(l) brierScoresAvg(apply(SPFT.agg2,2,function(z) probsLogitExtrem(z, l)),Z)),
type = "l",lwd=2, col="#C02F39",
xlab="Systematic Bias a",
ylab="Brier score")
brier.ext.plot <- recordPlot()
# p <- ggplot(data = data.frame(a = 0), mapping = aes(x = a))
# fun.1 <- function(a) a^2 + a
# fun.2 <- function(l) brierScoresAvg(apply(SPFT.agg2,2,function(z) probsLogitExtrem(z, l)),Z)
# p + stat_function(fun = fun.1) + xlim(-5,5)
# p + stat_function(fun = fun.2) + xlim(0,5)
# compute aggregated probabilities
probs.extrem<-apply(SPFT.agg2,2,function(z) probsLogitExtrem(z, a=1.58))
# plot simple means against extremized values
plot(probs.mean, probs.extrem, asp=1,ylim=c(0,1),xlim=c(0,1))
abline(0,1,lty=2)
points(Z,probs.mean,col=2,pch=16)
# 3. displaying aggregated forecasts #########################################
# plot with aggregated probabilties
# add: labels for vlines
# vlines at the wrong place, e.g. for 13 the extremized value is above .5
agg.plot <- function(q) {
ggplot(SPFT, aes(x=eval(parse(text = fq[q])))) +
geom_density(alpha=.3, fill="#C02F39") +
geom_vline(data=SPFT,
aes(xintercept=mean(eval(parse(text = fq[q])))),
linetype="dashed", size=1.5) + # group average
# vertical line for dropping case
geom_vline(data=filter(SPFT, bnt.s > 1 &
time.fq.sec.log > summary(SPFT$time.fq.sec.log)[2]),
aes(xintercept=mean(eval(parse(text = fq[q])))),
linetype="dashed", size=1.5, color = "yellow") + # group average
# vertical line for weighted probabilities
geom_vline(aes(xintercept=probs.mean.w.bnt.time[q]),
linetype="dashed", size=1.5, color = "orange") + # group average
# vertical line for extremized probability
geom_vline(aes(xintercept=probs.extrem[q]),
linetype="dashed", size=1.5, color = "red") + # group average
labs(title = sapply(strwrap(as.character(FQ[q,2]), 40, simplify=FALSE),
paste, collapse="\n" ),
x = "What is the probability of this event to happen?",
y = "Distribution of estimates") + # labels
expand_limits(x=c(0,1)) + # set range of x-axis
theme_bw() +
scale_x_continuous(labels=percent) # percentages
}
agg.plot(13)
###############################################################################
# 10. presentation forecasts
###############################################################################
# plot scores distributed by groups
brierPlot <- function(x){ggplot(SPFT, aes(x = brier.avg, fill = x)) +
geom_density(alpha = 0.3) +
#geom_histogram(binwidth=.05, position="dodge", fill = "#C02F39") + # bar type
theme_bw() +
theme(axis.title = element_text(size=18, family="Times"), # Labels axis font size
axis.text = element_text(size=14, family="Times")) +
labs( title = paste("Brier score distribution by ", substring(deparse(substitute(x)), 6)),
x = "Brier score",
y = "Frequency") # labels))
}
# formulars for trying out
brierPlot
brierPlot(as.factor(SPFT$team))
brierPlot <- function(x){ggplot(SPFT, aes(x = brier.avg, fill = x)) +
geom_density(alpha = 0.3) +
#geom_histogram(binwidth=.05, position="dodge", fill = "#C02F39") + # bar type
theme_bw() +
theme(axis.title = element_text(size=18), # Labels axis font size
axis.text = element_text(size=14)) +
labs( title = paste("Brier score distribution by ", substring(deparse(substitute(x)), 6)),
x = "Brier score",
y = "Frequency") # labels))
}
brierPlot <- function(x){ggplot(SPFT, aes(x = brier.avg, fill = x)) +
geom_density(alpha = 0.3) +
#geom_histogram(binwidth=.05, position="dodge", fill = "#C02F39") + # bar type
theme_bw() +
theme(axis.title = element_text(size=18), # Labels axis font size
axis.text = element_text(size=14)) +
labs( title = paste("Brier score distribution by ", substring(deparse(substitute(x)), 6)),
x = "Brier score",
y = "Frequency") # labels))
}
brierPlot(as.factor(SPFT$team))
